---
title: "Downloading data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE,
  comment = "#>"
)
```

Here we explain how to download data from the UNAIDS/[DHS](https://dhsprogram.com)
and UNICEF/[MICS](http://mics.unicef.org) servers. It works basically in 2 steps:

* first we need to download a **catalog** of data, which is a data frame that
contains the data sets available on the server. This is done thanks to the
function `get_catalog2()`.
* once we have this catalog of data, we can filter and mutate it in many ways
before using it to download the actual data to disk. This is done with the
function `lodown2()`.

These 2 steps can take a lot of time, so it is good that we do not do things that
have already be done and the function of `dhmics` take care of this. We will also
see at the end the pipeline function `load_dhs()` that combines these above 2
steps together with other, making the data query and very easy process. Note also
that both the [DHS](https://dhsprogram.com) and [MICS](http://mics.unicef.org)
servers requirea login and a password. [DHS](https://dhsprogram.com) additionally
requires a project's name that define the range of data that is available for
download.

## Before we start...

We will need of course the package `mics`, but also the package `dplyr` as well.
Note that there is a bug in the `dplyr::mutate()` function that has been reported [here](https://github.com/tidyverse/dplyr/issues/3884), among other. Until that
bug is fixed, we will use the `mutate2()` function from the package `dplyrx` that
is automatically installed and uploaded with `mics`. Compared to `dplyr::mutate()`,
`dplyrx::mutate2()` preserves the non-class attributes that we really need here
when working with catalogs of data. If these packages are not installed on your
system, install them:

```{r}
installed_packages <- rownames(installed.packages())
if (! "dplyr" %in% installed_packages) install.packages("dplyr")
if (! "devtools" %in% installed_packages) install.packages("devtools")
if (! "mics" %in% installed_packages) devtools::install_github("epix-project/mics")
```

And load them:

```{r message = FALSE}
library(dplyr)
library(mics)
```

## Defining a profile

The first thing to do is to define a profile once for all. This profile will be
used whenever needed. Here a profile is simply a named character vector that
contains the following 4 lines of information:

* `data`: the name of the data base that we want to query, either `"dhs"` or
`"mics"`. Note that a profile characterize one given project from one given
repository ([DHS](https://dhsprogram.com) or [MICS](http://mics.unicef.org));
* `email`: the email address used as a login for access to the server;
* `password`: the password used to access to the server and fitting to the email
address login;
* `project`: the name of the project. This is mandatory for queries to
[DHS](https://dhsprogram.com) only.

Here is an example of a profile:

```{r}
my_dhs_profile <- c(data     = "dhs",
                    email    = "marc.choisy@ird.fr",
                    password = "********",
                    project  = "My fake project on DHS")
```

(here the password is hidden, for obvious reasons.)

```{r include = FALSE}
my_dhs_profile <- c(data     = "dhs",
                    email    = "gerald.makuka@stx.ox.ac.uk",
                    password = "gerald22",
                    project  = "Antibiotics usage amongst under fiv")
```

## Downloading the catalog of data

Once the profile is defined, we can proceed to downlaod the catalog with the
function `get_catalog2`. This function is a wrapper around the
`lodown::get_catalog` function that allow to specify the profile. Downloading the
catalog of data corresponding to the defined profile is as simple as this:

```{r eval = FALSE}
my_dhs_catalog <- get_catalog2(my_dhs_profile)
```

```{r include = FALSE}
if (file.exists("my_dhs_catalog.rds")) {
  my_dhs_catalog <- readRDS("my_dhs_catalog.rds")
} else {
  my_dhs_catalog <- get_catalog2(my_dhs_profile)
  saveRDS(my_dhs_catalog, "my_dhs_catalog.rds")
}
```

Note that this step for example takes about **20 seconds** on a MacBook Pro. To
download the whole DHS data set on the same computer, it takes about **20 minutes**.
As mentioned above, the catalog of data is a mere data frame:

```{r}
names(my_dhs_catalog)
```

and

```{r}
dim(my_dhs_catalog)
```

and

```{r}
my_dhs_catalog %>% 
  select(-output_folder, -full_url) %>% 
  head()
```

and

```{r}
my_dhs_catalog %>% 
  select(-output_folder, -full_url) %>% 
  str()
```

Note that I selected out the variables `output_folder` and `full_url` as their
values are very long and the printing would have been a bit messy.

## Downloading specific data from the catalog

Once the catalog is downloaded, we can use it to `filter` or `mutate2` it the
way we want and then download the corresponding data sets to disk with the
`lodown2` function.

```{r include = FALSE}
my_dhs_catalog %>% 
  filter(year == 2015, country == "Tanzania", file_type == "KR") %>% 
  mutate2(output_folder = "dhs_data") %>% 
  lodown2()
```

```{r eval = FALSE}
my_dhs_catalog %>% 
  filter(year == 2015, country == "Tanzania", file_type == "KR") %>% 
  mutate2(output_folder = "dhs_data") %>% 
  lodown2()
```

Note here that we use the function `mutate2()` to overwrite the destination
folder we want to put our downloaded data files. Now, the last step consists in
uploading all these data file into the workspace. As simple as this:

```{r}
for(file in dir("dhs_data"))
  assign(sub(".rds", "", file), readRDS(paste0("dhs_data/", file)))
```

And here are our data files:

```{r}
ls()
```

In that case:

```{r}
dim(TZKR7AFL)
```

## Time efficiency of `get_catalog2()` and `lodown2()`

One very interesting aspect of `get_catalog2()` and `lodown2()` compare to
`lodown::get_catalog()` and `lodown::lodown()` is that they don't do things if
they can detect that they've already been, which, potentially, save a lot of
time. Demonstration: when there is no catalog in the working environment that
corresponds to the profile fed to `get_catalog2()`, it downloads it from the
server, which takes time:

```{r}
rm(my_dhs_catalog)
system.time(my_dhs_catalog <- get_catalog2(my_dhs_profile))
```

Once there is a catalog in the working environment that corresponds to the
profile fed to `get_catalog2()`, it just returns it, instantaneously:

```{r}
system.time(my_dhs_catalog <- get_catalog2(my_dhs_profile))
```

If there are more than one catalog in the working environment that correspond to
the profile fed to `get_catalog2()`, it informs the user and returns one of them:

```{r}
my_dhs_catalog2 <- my_dhs_catalog
my_dhs_catalog <- get_catalog2(my_dhs_profile)
```

Same thing for the `lodown2()` function: if the data files we aim to download
do not exist on disk, it downloads them as above. But if these files already
exist on disk, it doesn't download them again and informs the user that the files
already exist. It will download only the files that are not already on disk:

```{r}
my_dhs_catalog %>% 
  filter(year == 2015, country == "Tanzania", file_type == "KR") %>% 
  mutate2(output_folder = "dhs_data") %>% 
  lodown2()
```

## A pipeline

Finally, the function `load_dhs()` combines the following 4 steps once provided
a given profile:

* `get_catalog2()` downloads the catalog of data corresponding to the profile if
not already in the working environment;
* the catalog can be `filter()`ed according to inputed predicates;
* `lodown2()` downloads the data files corresponding to the `filter()`ed catalog
if they are not already on disk;
* the data are loaded from disk to the workspace if they are not already in there.

Demonstration: the above operations can be done in one go. For the purpose of the
demonstration, let's start from a virgin state:

```{r}
rm(my_dhs_catalog, my_dhs_catalog2, TZKR7AFL)
file.remove("dhs_data/TZKR7AFL.rds")
```

And let's time the pipeline:

```{r}
system.time(load_dhs(my_dhs_profile, year == 2015, country == "Tanzania", file_type == "KR", output = "dhs_data"))
```

This is particularly useful if we want to get a lot of data at once. Note also,
that this function benefits from the above-described time efficiencies of
`get_catalog2()` and `lodown2()`, and additionally does not load the data form
disk to the working environment is they are already there. Demonstration by
running the previous call a second time:

```{r}
system.time(load_dhs(my_dhs_profile, year == 2015, country == "Tanzania", file_type == "KR", output = "dhs_data"))
```
